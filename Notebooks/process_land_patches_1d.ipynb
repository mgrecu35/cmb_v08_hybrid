{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import torch\n",
    "fp=glob.glob('output_land_patches/patches_*.nc')\n",
    "fp=sorted(fp)\n",
    "land_fractL=[]\n",
    "tc_L=[]\n",
    "sfc_type_L=[]\n",
    "sk_temp_L=[]\n",
    "sk_temp1_L=[]\n",
    "xenc_L=[]\n",
    "xenc_prec_L=[]\n",
    "oe_wvp_L=[]\n",
    "near_sfc_precip_L=[]\n",
    "sfc_emiss_L=[]\n",
    "cldw_oe_L=[]\n",
    "sfc_bin_L=[]\n",
    "qv_L=[]\n",
    "import pickle\n",
    "\n",
    "#dense_autoencoder=torch.jit.load('dense_autoencoder.pt')\n",
    "#with open('scaler_qv.pkl','wb') as f:\n",
    "#    pickle.dump(scaler_qv,f)\n",
    "#scripted_model = torch.jit.script(model)\n",
    "#scripted_model.save('dense_autoencoder.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:41<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(886392, 13)\n"
     ]
    }
   ],
   "source": [
    "tc_L=[]\n",
    "sfc_type_L=[]\n",
    "sk_temp_L=[]\n",
    "sk_temp1_L=[]\n",
    "xenc_L=[]\n",
    "x_env_enc_L=[]\n",
    "xenc_prec_L=[]\n",
    "oe_wvp_L=[]\n",
    "near_sfc_precip_L=[]\n",
    "sfc_emiss_L=[]\n",
    "cldw_oe_L=[]\n",
    "sfc_bin_L=[]\n",
    "qv_L=[]\n",
    "from numba import jit\n",
    "@jit(nopython=True)\n",
    "def get_qv_sfc(qv,sfc_bin,qv_sfc):\n",
    "    n_patches,nscans,nrays,nlevs=qv.shape\n",
    "    for i in range(n_patches):\n",
    "        for j in range(nscans):\n",
    "            for k in range(nrays):\n",
    "                qv_sfc[i,j,k]=qv[i,j,k,sfc_bin[i,j,k]]\n",
    "    return qv_sfc\n",
    "import tqdm\n",
    "for f in tqdm.tqdm(fp[::]):\n",
    "    with nc.Dataset(f) as df:\n",
    "        tc_s1=df['tc_s1'][:]\n",
    "        tc_s2=df['tc_s2'][:]\n",
    "        surface_type=df['surface_type'][:]\n",
    "        sk_temp=df['sk_temp'][:]\n",
    "        qv=df['qv'][:]\n",
    "        qv_oe=df['qv_oe'][:]\n",
    "        cldw_oe=df['cldw_oe'][:]\n",
    "        oe_wvp=df['oe_wvp'][:]\n",
    "        near_sfc_precip=df['near_sfc_precip'][:]\n",
    "        sfc_emiss=df['sfc_emiss'][:]\n",
    "        sfc_bin=df['sfc_bin'][:]\n",
    "        x_enc_prec=df['x_enc'][:]\n",
    "        #print(tc_s1.shape)\n",
    "        n_patches=tc_s1.shape[0]\n",
    "        qv_sfc=get_qv_sfc(qv.data,sfc_bin.data,np.zeros((n_patches,tc_s1.shape[1],tc_s1.shape[2]),dtype=np.float32))\n",
    "        #print(qv_sfc.shape)\n",
    "        #print(qv_sfc.shape)\n",
    "        for i in range(n_patches):\n",
    "            a_nan=np.isnan(near_sfc_precip[i,:,24].data)\n",
    "            if sum(a_nan) > 0:\n",
    "                continue\n",
    "            if near_sfc_precip[i,:,24].data.min() <0:\n",
    "                continue\n",
    "            if oe_wvp[i,24].min() <0:\n",
    "                continue\n",
    "            if tc_s1[i,:,24,:].min() <0:\n",
    "                continue\n",
    "            if tc_s2[i,:,24,:].min() <0:\n",
    "                continue\n",
    "            tc_L.append(np.concatenate((tc_s1[i,:,24,:],tc_s2[i,:,24,:]),axis=-1))\n",
    "            sfc_type_L.append(surface_type[i,:,24])\n",
    "            sk_temp_L.append(sk_temp[i,:,24])\n",
    "            qv_L.append(qv_sfc[i,:,24])\n",
    "        #xenc_L.append(x_enc[i,:,:,:])\n",
    "        #x_env_enc_L.append(x_env_enc[i,:,:,:])\n",
    "            xenc_prec_L.append(x_enc_prec[i,:,24,:])\n",
    "            oe_wvp_L.append(oe_wvp[i,:,24])\n",
    "            sfc_emiss_L.append(sfc_emiss[i,:,24,:])\n",
    "            log_precip=np.log10(1+near_sfc_precip[i,:,24].data/0.1)\n",
    "            a_nan=np.nonzero(log_precip!=log_precip)\n",
    "            if len(a_nan[0]) > 0:\n",
    "                stop\n",
    "            near_sfc_precip_L.append(np.log10(1+near_sfc_precip[i,:,24]/0.1))\n",
    "        #break\n",
    "    #break\n",
    "tc_L=np.concatenate(tc_L,axis=0)\n",
    "sfc_type_L=np.concatenate(sfc_type_L,axis=0)\n",
    "sk_temp_L=np.concatenate(sk_temp_L,axis=0)\n",
    "xenc_prec_L=np.concatenate(xenc_prec_L,axis=0)\n",
    "oe_wvp_L=np.concatenate(oe_wvp_L,axis=0)\n",
    "sfc_emiss_L=np.concatenate(sfc_emiss_L,axis=0)\n",
    "near_sfc_precip_L=np.concatenate(near_sfc_precip_L,axis=0)\n",
    "qv_L=np.concatenate(qv_L,axis=0)\n",
    "print(tc_L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.038790476\n",
      "(886392,) (886392,)\n",
      "[[1.         0.80197684]\n",
      " [0.80197684 1.        ]]\n",
      "0 324\n",
      "(67009,)\n",
      "(819383,)\n"
     ]
    }
   ],
   "source": [
    "print(qv_L.min(),oe_wvp_L.min())\n",
    "print(qv_L.shape,oe_wvp_L.shape)\n",
    "\n",
    "print(np.corrcoef(qv_L,oe_wvp_L))\n",
    "print(sfc_type_L.min(),sfc_type_L.max())\n",
    "a=np.nonzero(sfc_type_L==0)\n",
    "print(a[0].shape)\n",
    "b=np.nonzero(sfc_type_L!=0)\n",
    "print(b[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 3.1356606 0.047525432\n",
      "(886392,)\n"
     ]
    }
   ],
   "source": [
    "print(near_sfc_precip_L.min(),near_sfc_precip_L.max(),near_sfc_precip_L.mean())\n",
    "print(near_sfc_precip_L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "tcX=xr.DataArray(tc_L,dims=['n_profiles','n_chans'],coords={'n_profiles':np.arange(tc_L.shape[0]),'n_chans':np.arange(tc_L.shape[1])})\n",
    "sfc_typeX=xr.DataArray(sfc_type_L,dims=['n_profiles'],coords={'n_profiles':np.arange(sfc_type_L.shape[0])})\n",
    "sk_tempX=xr.DataArray(sk_temp_L,dims=['n_profiles'],coords={'n_profiles':np.arange(sk_temp_L.shape[0])})\n",
    "qvX=xr.DataArray(qv_L,dims=['n_profiles'],coords={'n_profiles':np.arange(qv_L.shape[0])})\n",
    "oe_wvpX=xr.DataArray(oe_wvp_L,dims=['n_profiles'],coords={'n_profiles':np.arange(oe_wvp_L.shape[0])})\n",
    "near_sfc_precipX=xr.DataArray(near_sfc_precip_L,dims=['n_profiles'],coords={'n_profiles':np.arange(near_sfc_precip_L.shape[0])})\n",
    "x_enc_precX=xr.DataArray(xenc_prec_L,dims=['n_profiles','n_comp'],coords={'n_profiles':np.arange(xenc_prec_L.shape[0]),'n_comp':np.arange(xenc_prec_L.shape[1])})\n",
    "ds=xr.Dataset({'tc':tcX,'sfc_type':sfc_typeX,'sk_temp':sk_tempX,'qv':qvX,'oe_wvp':oe_wvpX,'near_sfc_precip':near_sfc_precipX,'x_enc_prec':x_enc_precX})\n",
    "comp = dict(zlib=True, complevel=5)\n",
    "encoding = {var: comp for var in ds.data_vars}\n",
    "ds.to_netcdf('training_1d_data_land.nc',encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tc': [array([262.15393, 242.96167, 263.8994 , 247.69026, 265.37137, 261.23865,\n",
      "       248.13664, 262.6147 , 255.16196, 263.83707, 261.55557, 255.9773 ,\n",
      "       262.22192], dtype=float32), array([31.05876 , 46.141956, 27.561977, 41.09737 , 24.578712, 28.132069,\n",
      "       37.89757 , 28.753544, 32.18047 , 24.599308, 26.546144,  9.781629,\n",
      "       15.644364], dtype=float32)], 'sfc_type': [111.37076710981147, 44.74047868686988], 'sk_temp': [283.65118, 19.78732], 'qv': [3.9666257, 4.375533], 'oe_wvp': [18.048836, 15.562971], 'near_sfc_precip': [0.047525432, 0.22921856], 'x_enc_prec': [array([-0.03576973, -0.01128846,  0.00253951, -0.04949954,  0.0063798 ,\n",
      "        0.03153232]), array([0.38198821, 0.30524483, 0.23588714, 0.39220661, 0.4068045 ,\n",
      "       0.24919357])]}\n"
     ]
    }
   ],
   "source": [
    "d_scaler={}\n",
    "for vars in ['tc','sfc_type','sk_temp','qv','oe_wvp','near_sfc_precip','x_enc_prec']:\n",
    "    #print(vars,ds[vars][:].mean(axis=0),ds[vars][:].std(axis=0))\n",
    "    d_scaler[vars]=[ds[vars][:].data.mean(axis=0),ds[vars][:].data.std(axis=0)]\n",
    "with open('scaler_1d_land.pkl','wb') as f:\n",
    "    pickle.dump(d_scaler,f)\n",
    "\n",
    "# write the d_scaler to a text file easy to read in Fortran\n",
    "with open('scaler_1d_land.txt', 'w') as f:\n",
    "    for key, value in d_scaler.items():\n",
    "        f.write(\"%s\\n\"%key)\n",
    "        mean_text=''\n",
    "        try:\n",
    "            for v in value[0]:\n",
    "                mean_text+=str(v)+' '\n",
    "        except:\n",
    "            mean_text+=str(value[0])+' '\n",
    "        f.write(\"%s\\n\"%mean_text)\n",
    "        std_text=''\n",
    "        try:\n",
    "            for v in value[1]:\n",
    "                std_text+=str(v)+' '\n",
    "        except:\n",
    "            std_text+=str(value[1])+' '\n",
    "        f.write(\"%s\\n\"%std_text)\n",
    "f.close()\n",
    "print(d_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111.37076710981147, 44.74047868686988]\n",
      "sfc_type\n"
     ]
    }
   ],
   "source": [
    "print(value)\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(886392, 6)\n",
      "(886392,)\n",
      "(886392,)\n"
     ]
    }
   ],
   "source": [
    "tc_scaled=(tcX.data-d_scaler['tc'][0])/d_scaler['tc'][1]\n",
    "sfc_type_scaled=(sfc_typeX.data-d_scaler['sfc_type'][0])/d_scaler['sfc_type'][1]\n",
    "sk_temp_scaled=(sk_tempX.data-d_scaler['sk_temp'][0])/d_scaler['sk_temp'][1]\n",
    "qv_scaled=(qvX.data-d_scaler['qv'][0])/d_scaler['qv'][1]\n",
    "oe_wvp_scaled=(oe_wvpX.data-d_scaler['oe_wvp'][0])/d_scaler['oe_wvp'][1]\n",
    "near_sfc_precip_scaled=(near_sfc_precipX.data-d_scaler['near_sfc_precip'][0])/d_scaler['near_sfc_precip'][1]\n",
    "x_enc_prec_scaled=(x_enc_precX.data-d_scaler['x_enc_prec'][0])/d_scaler['x_enc_prec'][1]\n",
    "print(x_enc_prec_scaled.shape)\n",
    "print(near_sfc_precip_scaled.shape)\n",
    "print(near_sfc_precip_L.shape)\n",
    "\n",
    "X_input=torch.tensor(np.concatenate((tc_scaled,sfc_type_scaled[:,np.newaxis],sk_temp_scaled[:,np.newaxis],qv_scaled[:,np.newaxis]),axis=-1),dtype=torch.float32)\n",
    "y_output=torch.tensor(np.concatenate((oe_wvp_scaled[:,np.newaxis],near_sfc_precip_scaled[:,np.newaxis],x_enc_prec_scaled),axis=-1),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntot=X_input.shape[0]\n",
    "n_train=int(0.8*ntot)\n",
    "import torch\n",
    "X_train=torch.utils.data.TensorDataset(X_input[:n_train],y_output[:n_train])\n",
    "X_test=torch.utils.data.TensorDataset(X_input[n_train:],y_output[n_train:])\n",
    "X_train_loader = torch.utils.data.DataLoader(X_train, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DenseModel, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 128)\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.05)\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.05)\n",
    "        self.fc3 = torch.nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        #x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        #x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "input_size = X_input.shape[1]\n",
    "output_size = y_output.shape[1]\n",
    "model = DenseModel(input_size, output_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "num_epochs = 50\n",
    "losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.4874\n",
      "Epoch [2/20], Loss: 0.4406\n",
      "Epoch [3/20], Loss: 0.4279\n",
      "Epoch [4/20], Loss: 0.4127\n",
      "Epoch [5/20], Loss: 0.4066\n",
      "Epoch [6/20], Loss: 0.3990\n",
      "Epoch [7/20], Loss: 0.3944\n",
      "Epoch [8/20], Loss: 0.3908\n",
      "Epoch [9/20], Loss: 0.3904\n",
      "Epoch [10/20], Loss: 0.3852\n",
      "Epoch [11/20], Loss: 0.3817\n",
      "Epoch [12/20], Loss: 0.3835\n",
      "Epoch [13/20], Loss: 0.3764\n",
      "Epoch [14/20], Loss: 0.3783\n",
      "Epoch [15/20], Loss: 0.3752\n",
      "Epoch [16/20], Loss: 0.3703\n",
      "Epoch [17/20], Loss: 0.3727\n",
      "Epoch [18/20], Loss: 0.3694\n",
      "Epoch [19/20], Loss: 0.3698\n",
      "Epoch [20/20], Loss: 0.3630\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = 0\n",
    "    icount=0\n",
    "    for i, (inputs, targets) in enumerate(X_train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss+=loss.item()\n",
    "        icount+=1\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss/icount:.4f}')\n",
    "torch.save(model.state_dict(), 'dense_model_land.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(1, 16, strides=[16, 1], requires_grad=0, device=cpu),\n",
      "      %fc1.weight : Float(128, 16, strides=[16, 1], requires_grad=1, device=cpu),\n",
      "      %fc1.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fc2.weight : Float(64, 128, strides=[128, 1], requires_grad=1, device=cpu),\n",
      "      %fc2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fc3.weight : Float(8, 64, strides=[64, 1], requires_grad=1, device=cpu),\n",
      "      %fc3.bias : Float(8, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %/fc1/Gemm_output_0 : Float(1, 128, strides=[128, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc1/Gemm\"](%input, %fc1.weight, %fc1.bias), scope: __main__.DenseModel::/torch.nn.modules.linear.Linear::fc1 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/linear.py:125:0\n",
      "  %/Relu_output_0 : Float(1, 128, strides=[128, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/Relu\"](%/fc1/Gemm_output_0), scope: __main__.DenseModel:: # /var/folders/x_/d2_jzyq50052xh1_tk02bnmc0000gq/T/ipykernel_80970/1304595632.py:11:0\n",
      "  %/fc2/Gemm_output_0 : Float(1, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc2/Gemm\"](%/Relu_output_0, %fc2.weight, %fc2.bias), scope: __main__.DenseModel::/torch.nn.modules.linear.Linear::fc2 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/linear.py:125:0\n",
      "  %/Relu_1_output_0 : Float(1, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/Relu_1\"](%/fc2/Gemm_output_0), scope: __main__.DenseModel:: # /var/folders/x_/d2_jzyq50052xh1_tk02bnmc0000gq/T/ipykernel_80970/1304595632.py:13:0\n",
      "  %output : Float(1, 8, strides=[8, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc3/Gemm\"](%/Relu_1_output_0, %fc3.weight, %fc3.bias), scope: __main__.DenseModel::/torch.nn.modules.linear.Linear::fc3 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/linear.py:125:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "torch.onnx.export(model, X_input[:1], 'xdense/xdense_model_land.onnx', export_params=True, verbose=True, input_names=['input'], output_names=['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ltL 28 Number of low resolution 5o grid intervals of latitude from 70oS to\n",
    "70oN.\n",
    "lnL 72 Number of low resolution 5o grid intervals of longitude from 180oW\n",
    "to 180oE.\n",
    "ltH 536 Number of high resolution 0.25o grid intervals of latitude from 67oS\n",
    "to 67oN.\n",
    "lnH 1440 Number of high resolution 0.25o grid intervals of longitude from\n",
    "180oW to 180oE.\n",
    "ns 2 Number of swaths:, 0 = Ku+TMI (full swath), 1 = Ku+TMI (narrow swath).\n",
    "hgt 16 Number of level heights 0-15: 0: near surface, 1-10: height = 1.0km\n",
    "* index, 11-15: height = 10.0km + 2.0km * (index-10),\n",
    "tim 24 Number of hourly local time bins.\n",
    "rt 3 Number of rain types: stratiform, convective, all.\n",
    "st 3 Number of surface types: ocean, land, all.\n",
    "bin 30 Number of bins in histogram.\n",
    "emiss 9 Number of radiometer channel emissivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.94885651]\n",
      " [0.94885651 1.        ]]\n",
      "[[1.         0.79672945]\n",
      " [0.79672945 1.        ]]\n",
      "[[1.         0.80390849]\n",
      " [0.80390849 1.        ]]\n",
      "[[1.         0.73388527]\n",
      " [0.73388527 1.        ]]\n",
      "[[1.         0.66082102]\n",
      " [0.66082102 1.        ]]\n",
      "[[1.         0.81777793]\n",
      " [0.81777793 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model(X_input[n_train:]).detach().numpy()\n",
    "y_test=y_output[n_train:].numpy()\n",
    "for i in range(6):\n",
    "    print(np.corrcoef(y_pred[:,i],y_test[:,i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
