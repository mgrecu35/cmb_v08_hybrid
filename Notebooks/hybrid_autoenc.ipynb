{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_hat shape: torch.Size([1, 13, 150, 49])\n",
      "y_hat shape: torch.Size([1, 9, 150, 49])\n",
      "Exported graph: graph(%input : Float(1, 29, 150, 49, strides=[213150, 7350, 49, 1], requires_grad=0, device=cpu),\n",
      "      %encoder.conv1.weight : Float(16, 29, 3, 3, strides=[261, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv1.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv2.weight : Float(32, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv2.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv3.weight : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv3.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.fc.weight : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.fc.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %decoder.fc.weight : Float(64, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %decoder.fc.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv1.weight : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv2.weight : Float(32, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv2.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv3.weight : Float(16, 13, 3, 3, strides=[117, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv3.bias : Float(13, strides=[1], requires_grad=1, device=cpu),\n",
      "      %regressor.fc.weight : Float(64, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %regressor.fc.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv1.weight : Float(96, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv2.weight : Float(48, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv2.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv3.weight : Float(16, 9, 3, 3, strides=[81, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv3.bias : Float(9, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape\"](%input), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant\"](), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_1\"](), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_2\"](), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Slice_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/Slice\"](%/Shape_output_0, %/Constant_1_output_0, %/Constant_2_output_0, %/Constant_output_0), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Constant_3_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 152   48 [ CPULongType{2} ], onnx_name=\"/Constant_3\"](), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat\"](%/Slice_output_0, %/Constant_3_output_0), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %onnx::Resize_33 : Tensor? = prim::Constant(), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %onnx::Resize_34 : Tensor? = prim::Constant(), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Resize_output_0 : Float(1, 29, 152, 48, strides=[211584, 7296, 48, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"half_pixel\", cubic_coeff_a=-0.75, mode=\"linear\", nearest_mode=\"floor\", onnx_name=\"/Resize\"](%input, %onnx::Resize_33, %onnx::Resize_34, %/Concat_output_0), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/encoder/conv1/Conv_output_0 : Float(1, 16, 152, 48, strides=[116736, 7296, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/conv1/Conv\"](%/Resize_output_0, %encoder.conv1.weight, %encoder.conv1.bias), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.conv.Conv2d::conv1 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/encoder/Relu_output_0 : Float(1, 16, 152, 48, strides=[116736, 7296, 48, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/encoder/Relu\"](%/encoder/conv1/Conv_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/encoder/pool/MaxPool_output_0 : Float(1, 16, 76, 24, strides=[29184, 1824, 24, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/encoder/pool/MaxPool\"](%/encoder/Relu_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.pooling.MaxPool2d::pool # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:830:0\n",
      "  %/encoder/conv2/Conv_output_0 : Float(1, 32, 76, 24, strides=[58368, 1824, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/conv2/Conv\"](%/encoder/pool/MaxPool_output_0, %encoder.conv2.weight, %encoder.conv2.bias), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.conv.Conv2d::conv2 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/encoder/Relu_1_output_0 : Float(1, 32, 76, 24, strides=[58368, 1824, 24, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/encoder/Relu_1\"](%/encoder/conv2/Conv_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/encoder/pool_1/MaxPool_output_0 : Float(1, 32, 38, 12, strides=[14592, 456, 12, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/encoder/pool_1/MaxPool\"](%/encoder/Relu_1_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.pooling.MaxPool2d::pool # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:830:0\n",
      "  %/encoder/conv3/Conv_output_0 : Float(1, 64, 38, 12, strides=[29184, 456, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/conv3/Conv\"](%/encoder/pool_1/MaxPool_output_0, %encoder.conv3.weight, %encoder.conv3.bias), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.conv.Conv2d::conv3 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/encoder/Relu_2_output_0 : Float(1, 64, 38, 12, strides=[29184, 456, 12, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/encoder/Relu_2\"](%/encoder/conv3/Conv_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/encoder/fc/Conv_output_0 : Float(1, 128, 38, 12, strides=[58368, 456, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/fc/Conv\"](%/encoder/Relu_2_output_0, %encoder.fc.weight, %encoder.fc.bias), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.conv.Conv2d::fc # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/decoder/fc/Conv_output_0 : Float(1, 64, 38, 12, strides=[29184, 456, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/decoder/fc/Conv\"](%/encoder/fc/Conv_output_0, %decoder.fc.weight, %decoder.fc.bias), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.conv.Conv2d::fc # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/decoder/upsample/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/decoder/upsample/Constant\"](), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %onnx::Resize_49 : Tensor? = prim::Constant(), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/decoder/upsample/Resize_output_0 : Float(1, 64, 76, 24, strides=[116736, 1824, 24, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/decoder/upsample/Resize\"](%/decoder/fc/Conv_output_0, %onnx::Resize_49, %/decoder/upsample/Constant_output_0), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/decoder/deconv1/ConvTranspose_output_0 : Float(1, 32, 76, 24, strides=[58368, 1824, 24, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/decoder/deconv1/ConvTranspose\"](%/decoder/upsample/Resize_output_0, %decoder.deconv1.weight, %decoder.deconv1.bias), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.conv.ConvTranspose2d::deconv1 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/decoder/Relu_output_0 : Float(1, 32, 76, 24, strides=[58368, 1824, 24, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/decoder/Relu\"](%/decoder/deconv1/ConvTranspose_output_0), scope: __main__.HybridModel::/__main__.Decoder::decoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/decoder/upsample_1/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/decoder/upsample_1/Constant\"](), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %onnx::Resize_56 : Tensor? = prim::Constant(), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/decoder/upsample_1/Resize_output_0 : Float(1, 32, 152, 48, strides=[233472, 7296, 48, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/decoder/upsample_1/Resize\"](%/decoder/Relu_output_0, %onnx::Resize_56, %/decoder/upsample_1/Constant_output_0), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/decoder/deconv2/ConvTranspose_output_0 : Float(1, 16, 152, 48, strides=[116736, 7296, 48, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/decoder/deconv2/ConvTranspose\"](%/decoder/upsample_1/Resize_output_0, %decoder.deconv2.weight, %decoder.deconv2.bias), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.conv.ConvTranspose2d::deconv2 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/decoder/Relu_1_output_0 : Float(1, 16, 152, 48, strides=[116736, 7296, 48, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/decoder/Relu_1\"](%/decoder/deconv2/ConvTranspose_output_0), scope: __main__.HybridModel::/__main__.Decoder::decoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/decoder/deconv3/ConvTranspose_output_0 : Float(1, 13, 152, 48, strides=[94848, 7296, 48, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/decoder/deconv3/ConvTranspose\"](%/decoder/Relu_1_output_0, %decoder.deconv3.weight, %decoder.deconv3.bias), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.conv.ConvTranspose2d::deconv3 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/Shape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_1\"](%/decoder/deconv3/ConvTranspose_output_0), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_4\"](), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_5\"](), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_6\"](), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Slice_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/Slice_1\"](%/Shape_1_output_0, %/Constant_5_output_0, %/Constant_6_output_0, %/Constant_4_output_0), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Constant_7_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 150   49 [ CPULongType{2} ], onnx_name=\"/Constant_7\"](), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat_1\"](%/Slice_1_output_0, %/Constant_7_output_0), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %onnx::Resize_69 : Tensor? = prim::Constant(), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %onnx::Resize_70 : Tensor? = prim::Constant(), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %output1 : Float(1, 13, 150, 49, strides=[95550, 7350, 49, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"half_pixel\", cubic_coeff_a=-0.75, mode=\"linear\", nearest_mode=\"floor\", onnx_name=\"/Resize_1\"](%/decoder/deconv3/ConvTranspose_output_0, %onnx::Resize_69, %onnx::Resize_70, %/Concat_1_output_0), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/regressor/fc/Conv_output_0 : Float(1, 64, 38, 12, strides=[29184, 456, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/regressor/fc/Conv\"](%/encoder/fc/Conv_output_0, %regressor.fc.weight, %regressor.fc.bias), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.conv.Conv2d::fc # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/regressor/upsample/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/regressor/upsample/Constant\"](), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %onnx::Resize_76 : Tensor? = prim::Constant(), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/regressor/upsample/Resize_output_0 : Float(1, 64, 76, 24, strides=[116736, 1824, 24, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/regressor/upsample/Resize\"](%/regressor/fc/Conv_output_0, %onnx::Resize_76, %/regressor/upsample/Constant_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/regressor/Concat_output_0 : Float(1, 96, 76, 24, strides=[175104, 1824, 24, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/regressor/Concat\"](%/regressor/upsample/Resize_output_0, %/encoder/Relu_1_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor # /var/folders/x_/d2_jzyq50052xh1_tk02bnmc0000gq/T/ipykernel_65806/1430070430.py:50:0\n",
      "  %/regressor/conv1/ConvTranspose_output_0 : Float(1, 32, 76, 24, strides=[58368, 1824, 24, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/regressor/conv1/ConvTranspose\"](%/regressor/Concat_output_0, %regressor.conv1.weight, %regressor.conv1.bias), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.conv.ConvTranspose2d::conv1 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/regressor/Relu_output_0 : Float(1, 32, 76, 24, strides=[58368, 1824, 24, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/regressor/Relu\"](%/regressor/conv1/ConvTranspose_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/regressor/upsample_1/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/regressor/upsample_1/Constant\"](), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %onnx::Resize_84 : Tensor? = prim::Constant(), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/regressor/upsample_1/Resize_output_0 : Float(1, 32, 152, 48, strides=[233472, 7296, 48, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/regressor/upsample_1/Resize\"](%/regressor/Relu_output_0, %onnx::Resize_84, %/regressor/upsample_1/Constant_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/regressor/Concat_1_output_0 : Float(1, 48, 152, 48, strides=[350208, 7296, 48, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/regressor/Concat_1\"](%/regressor/upsample_1/Resize_output_0, %/encoder/Relu_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor # /var/folders/x_/d2_jzyq50052xh1_tk02bnmc0000gq/T/ipykernel_65806/1430070430.py:53:0\n",
      "  %/regressor/conv2/ConvTranspose_output_0 : Float(1, 16, 152, 48, strides=[116736, 7296, 48, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/regressor/conv2/ConvTranspose\"](%/regressor/Concat_1_output_0, %regressor.conv2.weight, %regressor.conv2.bias), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.conv.ConvTranspose2d::conv2 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/regressor/Relu_1_output_0 : Float(1, 16, 152, 48, strides=[116736, 7296, 48, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/regressor/Relu_1\"](%/regressor/conv2/ConvTranspose_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/regressor/conv3/ConvTranspose_output_0 : Float(1, 9, 152, 48, strides=[65664, 7296, 48, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/regressor/conv3/ConvTranspose\"](%/regressor/Relu_1_output_0, %regressor.conv3.weight, %regressor.conv3.bias), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.conv.ConvTranspose2d::conv3 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/Shape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_2\"](%/regressor/conv3/ConvTranspose_output_0), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_8\"](), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Constant_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_9\"](), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_10\"](), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Slice_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/Slice_2\"](%/Shape_2_output_0, %/Constant_9_output_0, %/Constant_10_output_0, %/Constant_8_output_0), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Constant_11_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 150   49 [ CPULongType{2} ], onnx_name=\"/Constant_11\"](), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat_2\"](%/Slice_2_output_0, %/Constant_11_output_0), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %onnx::Resize_97 : Tensor? = prim::Constant(), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %onnx::Resize_98 : Tensor? = prim::Constant(), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  %output2 : Float(1, 9, 150, 49, strides=[66150, 7350, 49, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"half_pixel\", cubic_coeff_a=-0.75, mode=\"linear\", nearest_mode=\"floor\", onnx_name=\"/Resize_2\"](%/regressor/conv3/ConvTranspose_output_0, %onnx::Resize_97, %onnx::Resize_98, %/Concat_2_output_0), scope: __main__.HybridModel:: # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4693:0\n",
      "  return (%output1, %output2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, nf, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, nf, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(nf, nf*2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(nf*2, nf*4, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Conv2d(nf*4, latent_dim, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2 = F.relu(self.conv2(self.pool(x1)))\n",
    "        x3 = F.relu(self.conv3(self.pool(x2)))\n",
    "        z = self.fc(x3)\n",
    "        return z, [x1, x2, x3]\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, nf, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Conv2d(latent_dim, nf*4, kernel_size=3, padding=1)\n",
    "        self.deconv1 = nn.ConvTranspose2d(nf*4, nf*2, kernel_size=3, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(nf*2, nf, kernel_size=3, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(nf, out_channels, kernel_size=3, padding=1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = F.relu(self.deconv1(self.upsample(x)))\n",
    "        x = F.relu(self.deconv2(self.upsample(x)))\n",
    "        x_hat = self.deconv3(x)\n",
    "        return x_hat\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self, latent_dim, nf, out_channels):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.fc = nn.Conv2d(latent_dim, nf*4, kernel_size=3, padding=1)\n",
    "        self.conv1 = nn.ConvTranspose2d(nf*4+nf*2, nf*2, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.ConvTranspose2d(nf*2+nf, nf, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.ConvTranspose2d(nf, out_channels, kernel_size=3, padding=1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "    def forward(self, z, intermediate_outputs):\n",
    "        x1, x2, x3 = intermediate_outputs\n",
    "        x = self.fc(z)\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        y_hat = self.conv3(x)\n",
    "        return y_hat\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, in_channels, nf, latent_dim, rec_channels, out_channels):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.encoder = Encoder(in_channels, nf, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, nf, rec_channels)\n",
    "        self.regressor = Regressor(latent_dim, nf, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Rescale input from (n_batch, n_in_channels, 150, 49) to (n_batch, n_in_channels, 152, 48)\n",
    "        x = F.interpolate(x, size=(152, 48), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        z, intermediate_outputs = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        x_hat = F.interpolate(x_hat, size=(150, 49), mode='bilinear', align_corners=False)\n",
    "        y_hat = self.regressor(z, intermediate_outputs)\n",
    "        \n",
    "        # Rescale output from (n_batch, n_out_channels, 152, 48) to (n_batch, n_out_channels, 150, 49)\n",
    "        y_hat = F.interpolate(y_hat, size=(150, 49), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        return x_hat, y_hat\n",
    "\n",
    "# Example usage\n",
    "in_channels = 29\n",
    "rec_channels = 13\n",
    "latent_dim = 128\n",
    "out_channels = 9\n",
    "nx = 128\n",
    "ny = 48\n",
    "nf = 16\n",
    "\n",
    "hybrid_model = HybridModel(in_channels, nf, latent_dim, rec_channels, out_channels)\n",
    "\n",
    "# Example input\n",
    "x = torch.randn(1, in_channels, 150, 49)\n",
    "\n",
    "# Forward pass\n",
    "x_hat, y_hat = hybrid_model(x)\n",
    "\n",
    "print(\"x_hat shape:\", x_hat.shape)\n",
    "print(\"y_hat shape:\", y_hat.shape)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(hybrid_model, x, \"hybrid_model.onnx\", verbose=True, input_names=['input'], output_names=['output1', 'output2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
