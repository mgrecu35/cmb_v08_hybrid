{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralop.models import FNO\n",
    "import torch\n",
    "fop_model = FNO(n_modes=(8, 8), hidden_channels=32,\n",
    "                in_channels=19, out_channels=1)\n",
    "test_input=torch.randn(1,19,48,48)\n",
    "out=fop_model(test_input)\n",
    "print(out.shape)\n",
    "\n",
    "print(fop_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to develop a hybrid (part autoencoder, part u-net) model for dense regression.\n",
    "The input is a multi-channel image, e.g. 9 channels by 128 x 64 pixels. \n",
    "The model would take the input and produc\n",
    "Z,intermediate_output=encoder(X)\n",
    "X_hat=decoder(Z)\n",
    "Y_hat=regressor(Z,intemediate_output)\n",
    "The regressor would be a sequence of convolutional layers with connections to the encoder layers in a typical U-net fashion.\n",
    "Could you draft a model for this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(1, 9, 128, 64, strides=[73728, 8192, 64, 1], requires_grad=0, device=cpu),\n",
      "      %encoder.conv1.weight : Float(16, 9, 3, 3, strides=[81, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv1.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv2.weight : Float(32, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv2.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv3.weight : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv3.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.fc.weight : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.fc.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %decoder.fc.weight : Float(64, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %decoder.fc.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv1.weight : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv2.weight : Float(32, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv2.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv3.weight : Float(16, 9, 3, 3, strides=[81, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv3.bias : Float(9, strides=[1], requires_grad=1, device=cpu),\n",
      "      %regressor.fc.weight : Float(64, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %regressor.fc.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv1.weight : Float(96, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv2.weight : Float(48, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv2.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv3.weight : Float(16, 9, 3, 3, strides=[81, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv3.bias : Float(9, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %/encoder/conv1/Conv_output_0 : Float(1, 16, 128, 64, strides=[131072, 8192, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/conv1/Conv\"](%input, %encoder.conv1.weight, %encoder.conv1.bias), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.conv.Conv2d::conv1 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/encoder/Relu_output_0 : Float(1, 16, 128, 64, strides=[131072, 8192, 64, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/encoder/Relu\"](%/encoder/conv1/Conv_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/encoder/pool/MaxPool_output_0 : Float(1, 16, 64, 32, strides=[32768, 2048, 32, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/encoder/pool/MaxPool\"](%/encoder/Relu_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.pooling.MaxPool2d::pool # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:830:0\n",
      "  %/encoder/conv2/Conv_output_0 : Float(1, 32, 64, 32, strides=[65536, 2048, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/conv2/Conv\"](%/encoder/pool/MaxPool_output_0, %encoder.conv2.weight, %encoder.conv2.bias), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.conv.Conv2d::conv2 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/encoder/Relu_1_output_0 : Float(1, 32, 64, 32, strides=[65536, 2048, 32, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/encoder/Relu_1\"](%/encoder/conv2/Conv_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/encoder/pool_1/MaxPool_output_0 : Float(1, 32, 32, 16, strides=[16384, 512, 16, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/encoder/pool_1/MaxPool\"](%/encoder/Relu_1_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.pooling.MaxPool2d::pool # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:830:0\n",
      "  %/encoder/conv3/Conv_output_0 : Float(1, 64, 32, 16, strides=[32768, 512, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/conv3/Conv\"](%/encoder/pool_1/MaxPool_output_0, %encoder.conv3.weight, %encoder.conv3.bias), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.conv.Conv2d::conv3 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/encoder/Relu_2_output_0 : Float(1, 64, 32, 16, strides=[32768, 512, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/encoder/Relu_2\"](%/encoder/conv3/Conv_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/encoder/fc/Conv_output_0 : Float(1, 128, 32, 16, strides=[65536, 512, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/fc/Conv\"](%/encoder/Relu_2_output_0, %encoder.fc.weight, %encoder.fc.bias), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.conv.Conv2d::fc # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/decoder/fc/Conv_output_0 : Float(1, 64, 32, 16, strides=[32768, 512, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/decoder/fc/Conv\"](%/encoder/fc/Conv_output_0, %decoder.fc.weight, %decoder.fc.bias), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.conv.Conv2d::fc # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/decoder/upsample/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/decoder/upsample/Constant\"](), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %onnx::Resize_38 : Tensor? = prim::Constant(), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/decoder/upsample/Resize_output_0 : Float(1, 64, 64, 32, strides=[131072, 2048, 32, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/decoder/upsample/Resize\"](%/decoder/fc/Conv_output_0, %onnx::Resize_38, %/decoder/upsample/Constant_output_0), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/decoder/deconv1/ConvTranspose_output_0 : Float(1, 32, 64, 32, strides=[65536, 2048, 32, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/decoder/deconv1/ConvTranspose\"](%/decoder/upsample/Resize_output_0, %decoder.deconv1.weight, %decoder.deconv1.bias), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.conv.ConvTranspose2d::deconv1 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/decoder/Relu_output_0 : Float(1, 32, 64, 32, strides=[65536, 2048, 32, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/decoder/Relu\"](%/decoder/deconv1/ConvTranspose_output_0), scope: __main__.HybridModel::/__main__.Decoder::decoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/decoder/upsample_1/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/decoder/upsample_1/Constant\"](), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %onnx::Resize_45 : Tensor? = prim::Constant(), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/decoder/upsample_1/Resize_output_0 : Float(1, 32, 128, 64, strides=[262144, 8192, 64, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/decoder/upsample_1/Resize\"](%/decoder/Relu_output_0, %onnx::Resize_45, %/decoder/upsample_1/Constant_output_0), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/decoder/deconv2/ConvTranspose_output_0 : Float(1, 16, 128, 64, strides=[131072, 8192, 64, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/decoder/deconv2/ConvTranspose\"](%/decoder/upsample_1/Resize_output_0, %decoder.deconv2.weight, %decoder.deconv2.bias), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.conv.ConvTranspose2d::deconv2 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/decoder/Relu_1_output_0 : Float(1, 16, 128, 64, strides=[131072, 8192, 64, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/decoder/Relu_1\"](%/decoder/deconv2/ConvTranspose_output_0), scope: __main__.HybridModel::/__main__.Decoder::decoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %output1 : Float(1, 9, 128, 64, strides=[73728, 8192, 64, 1], requires_grad=1, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/decoder/deconv3/ConvTranspose\"](%/decoder/Relu_1_output_0, %decoder.deconv3.weight, %decoder.deconv3.bias), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.conv.ConvTranspose2d::deconv3 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/regressor/fc/Conv_output_0 : Float(1, 64, 32, 16, strides=[32768, 512, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/regressor/fc/Conv\"](%/encoder/fc/Conv_output_0, %regressor.fc.weight, %regressor.fc.bias), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.conv.Conv2d::fc # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/regressor/upsample/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/regressor/upsample/Constant\"](), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %onnx::Resize_54 : Tensor? = prim::Constant(), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/regressor/upsample/Resize_output_0 : Float(1, 64, 64, 32, strides=[131072, 2048, 32, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/regressor/upsample/Resize\"](%/regressor/fc/Conv_output_0, %onnx::Resize_54, %/regressor/upsample/Constant_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/regressor/Concat_output_0 : Float(1, 96, 64, 32, strides=[196608, 2048, 32, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/regressor/Concat\"](%/regressor/upsample/Resize_output_0, %/encoder/Relu_1_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor # /var/folders/x_/d2_jzyq50052xh1_tk02bnmc0000gq/T/ipykernel_534/3925834845.py:51:0\n",
      "  %/regressor/conv1/ConvTranspose_output_0 : Float(1, 32, 64, 32, strides=[65536, 2048, 32, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/regressor/conv1/ConvTranspose\"](%/regressor/Concat_output_0, %regressor.conv1.weight, %regressor.conv1.bias), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.conv.ConvTranspose2d::conv1 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/regressor/Relu_output_0 : Float(1, 32, 64, 32, strides=[65536, 2048, 32, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/regressor/Relu\"](%/regressor/conv1/ConvTranspose_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/regressor/upsample_1/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/regressor/upsample_1/Constant\"](), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %onnx::Resize_62 : Tensor? = prim::Constant(), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/regressor/upsample_1/Resize_output_0 : Float(1, 32, 128, 64, strides=[262144, 8192, 64, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/regressor/upsample_1/Resize\"](%/regressor/Relu_output_0, %onnx::Resize_62, %/regressor/upsample_1/Constant_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/regressor/Concat_1_output_0 : Float(1, 48, 128, 64, strides=[393216, 8192, 64, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/regressor/Concat_1\"](%/regressor/upsample_1/Resize_output_0, %/encoder/Relu_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor # /var/folders/x_/d2_jzyq50052xh1_tk02bnmc0000gq/T/ipykernel_534/3925834845.py:54:0\n",
      "  %/regressor/conv2/ConvTranspose_output_0 : Float(1, 16, 128, 64, strides=[131072, 8192, 64, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/regressor/conv2/ConvTranspose\"](%/regressor/Concat_1_output_0, %regressor.conv2.weight, %regressor.conv2.bias), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.conv.ConvTranspose2d::conv2 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/regressor/Relu_1_output_0 : Float(1, 16, 128, 64, strides=[131072, 8192, 64, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/regressor/Relu_1\"](%/regressor/conv2/ConvTranspose_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %output2 : Float(1, 9, 128, 64, strides=[73728, 8192, 64, 1], requires_grad=1, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/regressor/conv3/ConvTranspose\"](%/regressor/Relu_1_output_0, %regressor.conv3.weight, %regressor.conv3.bias), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.conv.ConvTranspose2d::conv3 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  return (%output1, %output2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, nf,latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, nf, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(nf, nf*2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(nf*2, nf*4, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Conv2d(nf*4, latent_dim, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2 = F.relu(self.conv2(self.pool(x1)))\n",
    "        x3 = F.relu(self.conv3(self.pool(x2)))\n",
    "        z = self.fc(x3)\n",
    "        return z, [x1, x2, x3]\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, nf, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Conv2d(latent_dim, nf*4, kernel_size=3, padding=1)\n",
    "        self.deconv1 = nn.ConvTranspose2d(nf*4, nf*2, kernel_size=3, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(nf*2, nf, kernel_size=3, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(nf, out_channels, kernel_size=3, padding=1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = F.relu(self.deconv1(self.upsample(x)))\n",
    "        x = F.relu(self.deconv2(self.upsample(x)))\n",
    "        x_hat =self.deconv3(x)\n",
    "        return x_hat\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self, latent_dim, nf, out_channels):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.fc = nn.Conv2d(latent_dim, nf*4, kernel_size=3, padding=1)\n",
    "        self.conv1 = nn.ConvTranspose2d(nf*4+nf*2, nf*2, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.ConvTranspose2d(nf*2+nf, nf, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.ConvTranspose2d(nf, out_channels, kernel_size=3, padding=1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "    def forward(self, z, intermediate_outputs):\n",
    "        x1, x2, x3 = intermediate_outputs\n",
    "        x = self.fc(z)\n",
    "        x = self.upsample(x)\n",
    "        #print(x.shape,x2.shape)\n",
    "        x = torch.concat([x, x2], dim=1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.upsample(x)\n",
    "        x = torch.concat([x, x1], dim=1)\n",
    "        #print(x.shape,'[x,x1]')\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        y_hat = x\n",
    "        return y_hat\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, in_channels, nf, latent_dim, out_channels):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.encoder = Encoder(in_channels, nf, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, nf, in_channels)\n",
    "        self.regressor = Regressor(latent_dim, nf, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, intermediate_outputs = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        y_hat = self.regressor(z, intermediate_outputs)\n",
    "        return x_hat, y_hat\n",
    "\n",
    "# Example usage\n",
    "in_channels = 9\n",
    "latent_dim = 128\n",
    "out_channels = 9\n",
    "#model = HybridModel(in_channels, latent_dim, out_channels)\n",
    "nx = 128\n",
    "ny = 64\n",
    "nf = 16\n",
    "model_encoder = Encoder(in_channels, nf, latent_dim)\n",
    "model_decoder = Decoder(latent_dim, nf, out_channels)\n",
    "# Example input\n",
    "x = torch.randn(1, in_channels, 128, 64)\n",
    "#x_hat = model(x)\n",
    "z, intermediate_outputs = model_encoder(x)\n",
    "\n",
    "#print(x_hat.shape)\n",
    "#print(z.shape)\n",
    "#for x in intermediate_outputs:\n",
    "#    print('int_shape',x.shape)\n",
    "\n",
    "hybrid_model = HybridModel(in_channels, nf, latent_dim, out_channels)\n",
    "torch.onnx.export(hybrid_model, x, \"hybrid_model.onnx\", verbose=True, input_names = ['input'], output_names = ['output1', 'output2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12838, 9, 128, 64)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "fs=sorted(glob.glob(\"tb_patches_2020*.npz\"))\n",
    "X=[]\n",
    "col_wv=[]\n",
    "col_cloud_liq=[]\n",
    "near_sfc_rain=[]\n",
    "for f in fs[:80]:\n",
    "    d=np.load(f)\n",
    "    X.extend(d['tb_patches'].astype(np.float32))\n",
    "    col_wv.extend(d['col_wv_OE'])\n",
    "    d_temp=d['near_sfc_rain']\n",
    "    a=np.nonzero(d_temp>-0.01)\n",
    "    d_temp[a]=np.log10(1+d_temp[a]/0.1)\n",
    "    near_sfc_rain.extend(d_temp.copy())\n",
    "    col_cloud_liq.extend(d['col_cloud_liquid'])\n",
    "X=np.array(X)\n",
    "X=np.moveaxis(X,3,1)\n",
    "X=X.astype(np.float32)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_wv=np.array(col_wv)\n",
    "\n",
    "np.mean(col_wv[a]),np.std(col_wv[a])\n",
    "col_cloud_liq=np.array(col_cloud_liq)\n",
    "a=np.nonzero(col_cloud_liq>=0)\n",
    "np.mean(col_cloud_liq[a]),np.std(col_cloud_liq[a])\n",
    "col_cloud_liq_mean=np.mean(col_cloud_liq[a])\n",
    "col_cloud_liq_std=np.std(col_cloud_liq[a])\n",
    "near_sfc_rain=np.array(near_sfc_rain)\n",
    "a=np.nonzero(near_sfc_rain>=0)\n",
    "np.mean(near_sfc_rain[a]),np.std(near_sfc_rain[a])\n",
    "near_sfc_rain_mean=np.mean(near_sfc_rain[a])\n",
    "near_sfc_rain_std=np.std(near_sfc_rain[a])\n",
    "a=np.nonzero(col_wv>=0)\n",
    "col_wv_mean=np.mean(col_wv[a])\n",
    "col_wv_std=np.std(col_wv[a])\n",
    "y_target=np.concatenate([col_wv[:,np.newaxis,:,:],col_cloud_liq[:,np.newaxis,:,:],near_sfc_rain[:,np.newaxis,:]],axis=1)\n",
    "\n",
    "mask_y=(y_target>=0).astype(np.float32)\n",
    "y_target[:,0,:,:]=(y_target[:,0,:,:]-col_wv_mean)/col_wv_std\n",
    "y_target[:,1,:,:]=(y_target[:,1,:,:]-col_cloud_liq_mean)/col_cloud_liq_std\n",
    "y_target[:,2,:,:]=(y_target[:,2,:,:]-near_sfc_rain_mean)/near_sfc_rain_std\n",
    "\n",
    "near_sfc_rain=np.array(near_sfc_rain)\n",
    "col_wv=np.array(col_wv)\n",
    "col_cloud_liq=np.array(col_cloud_liq)\n",
    "X_mean=X.mean(axis=0)\n",
    "X_std=X.std(axis=0)\n",
    "X_norm=(X-X_mean)/X_std\n",
    "import pickle\n",
    "d={'X_mean':X_mean,'X_std':X_std,'col_wv_mean':col_wv_mean,'col_wv_std':col_wv_std,'col_cloud_liq_mean':col_cloud_liq_mean,'col_cloud_liq_std':col_cloud_liq_std,'near_sfc_rain_mean':near_sfc_rain_mean,'near_sfc_rain_std':near_sfc_rain_std}\n",
    "pickle.dump(d,open('tb_target_mean_std.pkl','wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "n_all=X_norm.shape[0]\n",
    "nt=int(n_all*0.8)\n",
    "X_torch=torch.tensor(X_norm[:nt],dtype=torch.float32)\n",
    "y_torch=torch.tensor(y_target[:nt],dtype=torch.float32)\n",
    "mask_torch=torch.tensor(mask_y[:nt],dtype=torch.float32) \n",
    "model = HybridModel(in_channels=9, nf=16, latent_dim=16, out_channels=3)\n",
    "dataset = torch.utils.data.TensorDataset(X_torch, y_torch,mask_torch)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.28787616036855546\n",
      "Epoch 2/5, Loss: 0.15871282834037442\n",
      "Epoch 3/5, Loss: 0.14581949068842648\n",
      "Epoch 4/5, Loss: 0.1308806903683508\n",
      "Epoch 5/5, Loss: 0.1265457313844348\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epochs = 5\n",
    "for epoch in range(n_epochs):\n",
    "    avg_loss = 0\n",
    "    for inputs, target, mask_ in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs, y_ = model(inputs)\n",
    "        loss1 = criterion(outputs, inputs)\n",
    "        loss2 = criterion(y_*mask_, target*mask_)\n",
    "        loss=loss1+loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {avg_loss/len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 64 but got size 32 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#scripted_model.save(\"model_hybrid_2outputs_retrained.pt\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#model=torch.jit.script(model)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m x_rec, y_pred\u001b[38;5;241m=\u001b[39mmodel(X_test_torch)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_torch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_hybrid_2outputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/onnx/__init__.py:383\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, dynamic_axes, keep_initializers_as_inputs, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining, **_)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_shapes:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe exporter only supports dynamic shapes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthrough parameter dynamic_axes when dynamo=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    381\u001b[0m     )\n\u001b[0;32m--> 383\u001b[0m \u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/onnx/utils.py:495\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;241m+\u001b[39m (kwargs,)\n\u001b[0;32m--> 495\u001b[0m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/onnx/utils.py:1428\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1425\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1426\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1428\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1430\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m custom_opsets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1442\u001b[0m     custom_opsets \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/onnx/utils.py:1053\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m   1052\u001b[0m model \u001b[38;5;241m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[0;32m-> 1053\u001b[0m graph, params, torch_out, module \u001b[38;5;241m=\u001b[39m \u001b[43m_create_jit_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1054\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/onnx/utils.py:937\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    932\u001b[0m     graph \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[1;32m    933\u001b[0m         graph, flattened_args, param_count_list, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    934\u001b[0m     )\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, params, torch_out, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m graph, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_and_get_graph_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    939\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/onnx/utils.py:844\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    842\u001b[0m prev_autocast_cache_enabled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    843\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 844\u001b[0m trace_graph, torch_out, inputs_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[1;32m    853\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/jit/_trace.py:1498\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1497\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[0;32m-> 1498\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mONNXTracedModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/jit/_trace.py:138\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(out_vars)\n\u001b[0;32m--> 138\u001b[0m graph, _out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_by_tracing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_vars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_create_interpreter_name_lookup_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, outs[\u001b[38;5;241m0\u001b[39m], ret_inputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/jit/_trace.py:129\u001b[0m, in \u001b[0;36mONNXTracedModule.forward.<locals>.wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    128\u001b[0m     inputs_states\u001b[38;5;241m.\u001b[39mappend(_unflatten(in_args, in_desc))\n\u001b[0;32m--> 129\u001b[0m outs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrace_inputs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    131\u001b[0m     inputs_states[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m (inputs_states[\u001b[38;5;241m0\u001b[39m], trace_inputs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1727\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1729\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[0;32mIn[52], line 71\u001b[0m, in \u001b[0;36mHybridModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m z, intermediate_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[1;32m     70\u001b[0m x_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z)\n\u001b[0;32m---> 71\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintermediate_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_hat, y_hat\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1727\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1729\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[0;32mIn[52], line 51\u001b[0m, in \u001b[0;36mRegressor.forward\u001b[0;34m(self, z, intermediate_outputs)\u001b[0m\n\u001b[1;32m     49\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsample(x)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#print(x.shape,x2.shape)\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))\n\u001b[1;32m     53\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsample(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 32 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "#scripted_model = torch.jit.script(model)\n",
    "X_test_torch=torch.tensor(X_norm[nt:],dtype=torch.float32)\n",
    "#scripted_model.save(\"model_hybrid_2outputs_retrained.pt\")\n",
    "#model=torch.jit.script(model)\n",
    "x_rec, y_pred=model(X_test_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(1, 9, 128, 64, strides=[73728, 1, 576, 9], requires_grad=0, device=cpu),\n",
      "      %encoder.conv1.weight : Float(16, 9, 3, 3, strides=[81, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv1.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv2.weight : Float(32, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv2.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv3.weight : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.conv3.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.fc.weight : Float(16, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.fc.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %decoder.fc.weight : Float(64, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %decoder.fc.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv1.weight : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv2.weight : Float(32, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv2.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv3.weight : Float(16, 9, 3, 3, strides=[81, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %decoder.deconv3.bias : Float(9, strides=[1], requires_grad=1, device=cpu),\n",
      "      %regressor.fc.weight : Float(64, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %regressor.fc.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv1.weight : Float(96, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv2.weight : Float(48, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv2.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv3.weight : Float(16, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %regressor.conv3.bias : Float(3, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %/encoder/conv1/Conv_output_0 : Float(1, 16, 128, 64, strides=[131072, 1, 1024, 16], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/conv1/Conv\"](%input, %encoder.conv1.weight, %encoder.conv1.bias), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.conv.Conv2d::conv1 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/encoder/Relu_output_0 : Float(1, 16, 128, 64, strides=[131072, 1, 1024, 16], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/encoder/Relu\"](%/encoder/conv1/Conv_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/encoder/pool/MaxPool_output_0 : Float(1, 16, 64, 32, strides=[32768, 1, 512, 16], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/encoder/pool/MaxPool\"](%/encoder/Relu_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.pooling.MaxPool2d::pool # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:830:0\n",
      "  %/encoder/conv2/Conv_output_0 : Float(1, 32, 64, 32, strides=[65536, 1, 1024, 32], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/conv2/Conv\"](%/encoder/pool/MaxPool_output_0, %encoder.conv2.weight, %encoder.conv2.bias), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.conv.Conv2d::conv2 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/encoder/Relu_1_output_0 : Float(1, 32, 64, 32, strides=[65536, 1, 1024, 32], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/encoder/Relu_1\"](%/encoder/conv2/Conv_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/encoder/pool_1/MaxPool_output_0 : Float(1, 32, 32, 16, strides=[16384, 1, 512, 32], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/encoder/pool_1/MaxPool\"](%/encoder/Relu_1_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.pooling.MaxPool2d::pool # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:830:0\n",
      "  %/encoder/conv3/Conv_output_0 : Float(1, 64, 32, 16, strides=[32768, 1, 1024, 64], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/conv3/Conv\"](%/encoder/pool_1/MaxPool_output_0, %encoder.conv3.weight, %encoder.conv3.bias), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.conv.Conv2d::conv3 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/encoder/Relu_2_output_0 : Float(1, 64, 32, 16, strides=[32768, 1, 1024, 64], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/encoder/Relu_2\"](%/encoder/conv3/Conv_output_0), scope: __main__.HybridModel::/__main__.Encoder::encoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/encoder/fc/Conv_output_0 : Float(1, 16, 32, 16, strides=[8192, 1, 256, 16], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/fc/Conv\"](%/encoder/Relu_2_output_0, %encoder.fc.weight, %encoder.fc.bias), scope: __main__.HybridModel::/__main__.Encoder::encoder/torch.nn.modules.conv.Conv2d::fc # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/decoder/fc/Conv_output_0 : Float(1, 64, 32, 16, strides=[32768, 1, 1024, 64], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/decoder/fc/Conv\"](%/encoder/fc/Conv_output_0, %decoder.fc.weight, %decoder.fc.bias), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.conv.Conv2d::fc # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/decoder/upsample/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/decoder/upsample/Constant\"](), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %onnx::Resize_38 : Tensor? = prim::Constant(), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/decoder/upsample/Resize_output_0 : Float(1, 64, 64, 32, strides=[131072, 1, 2048, 64], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/decoder/upsample/Resize\"](%/decoder/fc/Conv_output_0, %onnx::Resize_38, %/decoder/upsample/Constant_output_0), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/decoder/deconv1/ConvTranspose_output_0 : Float(1, 32, 64, 32, strides=[65536, 1, 1024, 32], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/decoder/deconv1/ConvTranspose\"](%/decoder/upsample/Resize_output_0, %decoder.deconv1.weight, %decoder.deconv1.bias), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.conv.ConvTranspose2d::deconv1 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/decoder/Relu_output_0 : Float(1, 32, 64, 32, strides=[65536, 1, 1024, 32], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/decoder/Relu\"](%/decoder/deconv1/ConvTranspose_output_0), scope: __main__.HybridModel::/__main__.Decoder::decoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/decoder/upsample_1/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/decoder/upsample_1/Constant\"](), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %onnx::Resize_45 : Tensor? = prim::Constant(), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/decoder/upsample_1/Resize_output_0 : Float(1, 32, 128, 64, strides=[262144, 1, 2048, 32], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/decoder/upsample_1/Resize\"](%/decoder/Relu_output_0, %onnx::Resize_45, %/decoder/upsample_1/Constant_output_0), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/decoder/deconv2/ConvTranspose_output_0 : Float(1, 16, 128, 64, strides=[131072, 1, 1024, 16], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/decoder/deconv2/ConvTranspose\"](%/decoder/upsample_1/Resize_output_0, %decoder.deconv2.weight, %decoder.deconv2.bias), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.conv.ConvTranspose2d::deconv2 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/decoder/Relu_1_output_0 : Float(1, 16, 128, 64, strides=[131072, 1, 1024, 16], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/decoder/Relu_1\"](%/decoder/deconv2/ConvTranspose_output_0), scope: __main__.HybridModel::/__main__.Decoder::decoder # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %output1 : Float(1, 9, 128, 64, strides=[73728, 1, 576, 9], requires_grad=1, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/decoder/deconv3/ConvTranspose\"](%/decoder/Relu_1_output_0, %decoder.deconv3.weight, %decoder.deconv3.bias), scope: __main__.HybridModel::/__main__.Decoder::decoder/torch.nn.modules.conv.ConvTranspose2d::deconv3 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/regressor/fc/Conv_output_0 : Float(1, 64, 32, 16, strides=[32768, 1, 1024, 64], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/regressor/fc/Conv\"](%/encoder/fc/Conv_output_0, %regressor.fc.weight, %regressor.fc.bias), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.conv.Conv2d::fc # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549:0\n",
      "  %/regressor/upsample/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/regressor/upsample/Constant\"](), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %onnx::Resize_54 : Tensor? = prim::Constant(), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/regressor/upsample/Resize_output_0 : Float(1, 64, 64, 32, strides=[131072, 1, 2048, 64], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/regressor/upsample/Resize\"](%/regressor/fc/Conv_output_0, %onnx::Resize_54, %/regressor/upsample/Constant_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/regressor/Concat_output_0 : Float(1, 96, 64, 32, strides=[196608, 1, 3072, 96], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/regressor/Concat\"](%/regressor/upsample/Resize_output_0, %/encoder/Relu_1_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor # /var/folders/x_/d2_jzyq50052xh1_tk02bnmc0000gq/T/ipykernel_534/3925834845.py:51:0\n",
      "  %/regressor/conv1/ConvTranspose_output_0 : Float(1, 32, 64, 32, strides=[65536, 1, 1024, 32], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/regressor/conv1/ConvTranspose\"](%/regressor/Concat_output_0, %regressor.conv1.weight, %regressor.conv1.bias), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.conv.ConvTranspose2d::conv1 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/regressor/Relu_output_0 : Float(1, 32, 64, 32, strides=[65536, 1, 1024, 32], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/regressor/Relu\"](%/regressor/conv1/ConvTranspose_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/regressor/upsample_1/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/regressor/upsample_1/Constant\"](), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %onnx::Resize_62 : Tensor? = prim::Constant(), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/regressor/upsample_1/Resize_output_0 : Float(1, 32, 128, 64, strides=[262144, 1, 2048, 32], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/regressor/upsample_1/Resize\"](%/regressor/Relu_output_0, %onnx::Resize_62, %/regressor/upsample_1/Constant_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.upsampling.Upsample::upsample # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:4649:0\n",
      "  %/regressor/Concat_1_output_0 : Float(1, 48, 128, 64, strides=[393216, 1, 3072, 48], requires_grad=1, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/regressor/Concat_1\"](%/regressor/upsample_1/Resize_output_0, %/encoder/Relu_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor # /var/folders/x_/d2_jzyq50052xh1_tk02bnmc0000gq/T/ipykernel_534/3925834845.py:54:0\n",
      "  %/regressor/conv2/ConvTranspose_output_0 : Float(1, 16, 128, 64, strides=[131072, 1, 1024, 16], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/regressor/conv2/ConvTranspose\"](%/regressor/Concat_1_output_0, %regressor.conv2.weight, %regressor.conv2.bias), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.conv.ConvTranspose2d::conv2 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  %/regressor/Relu_1_output_0 : Float(1, 16, 128, 64, strides=[131072, 1, 1024, 16], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/regressor/Relu_1\"](%/regressor/conv2/ConvTranspose_output_0), scope: __main__.HybridModel::/__main__.Regressor::regressor # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %output2 : Float(1, 3, 128, 64, strides=[24576, 1, 192, 3], requires_grad=1, device=cpu) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/regressor/conv3/ConvTranspose\"](%/regressor/Relu_1_output_0, %regressor.conv3.weight, %regressor.conv3.bias), scope: __main__.HybridModel::/__main__.Regressor::regressor/torch.nn.modules.conv.ConvTranspose2d::conv3 # /Users/mgrecu/miniforge3/lib/python3.12/site-packages/torch/nn/modules/conv.py:1162:0\n",
      "  return (%output1, %output2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, X_test_torch[:1,:,:,:], \"model_hybrid_2outputs\", verbose=True, input_names=['input'], output_names=['output1','output2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9515082 0.9310476\n",
      "0.7816973 0.7929131\n",
      "2.7854583 2.1225977\n",
      "0.9850911541276295\n",
      "0.8748352806303226\n",
      "0.8127180724370588\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_numpy=y_pred.detach().numpy()\n",
    "y_target_test=y_target[nt:]\n",
    "col_wv_test=col_wv[nt:]\n",
    "a=np.nonzero(col_wv_test[:,:,:]>0)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "h2=plt.hist2d(y_target_test[:,0,:,:][a],y_pred_numpy[:,0,:,:][a],bins=np.arange(100)*0.1-2,norm=matplotlib.colors.LogNorm(),cmap='jet')\n",
    "np.corrcoef(y_target_test[:,0,:,:][a].flatten(),y_pred_numpy[:,0,:,:][a].flatten())\n",
    "for i in range(3):\n",
    "    a=np.nonzero(y_target_test[:,i,:,:]>0)\n",
    "    print(y_target_test[:,i,:,:][a].mean(),y_pred_numpy[:,i,:,:][a].mean())\n",
    "\n",
    "for i in range(3):\n",
    "    a=np.nonzero(y_target_test[:,i,:,:]>0)\n",
    "    print(np.corrcoef(y_target_test[:,i,:,:][a].flatten(),y_pred_numpy[:,i,:,:][a].flatten())[0,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
